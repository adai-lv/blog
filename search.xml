<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Kafka 安装配置和常用命令</title>
      <link href="/articles/kafka/an-zhuang-pei-zhi-he-chang-yong-ming-ling.html"/>
      <url>/articles/kafka/an-zhuang-pei-zhi-he-chang-yong-ming-ling.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>系统环境：MacOS<br>Kafka 版本：2.3.1</p></blockquote><h2 id="Homebrew安装Kafka"><a href="#Homebrew安装Kafka" class="headerlink" title="Homebrew安装Kafka"></a>Homebrew安装Kafka</h2><blockquote><p>安装 kafka 过程中会自动的安装好 zookeeper</p></blockquote><pre><code>$ brew info kafka$ brew install kafka$ cd /usr/local/Cellar/kafka/2.3.1/libexec</code></pre><h2 id="卸载-Kafka"><a href="#卸载-Kafka" class="headerlink" title="卸载 Kafka"></a>卸载 Kafka</h2><pre><code>$ brew uninstall kafka</code></pre><h2 id="配置文件设置"><a href="#配置文件设置" class="headerlink" title="配置文件设置"></a>配置文件设置</h2><blockquote><p>配置文件路径：/usr/local/etc/kafka</p></blockquote><h3 id="server-properties"><a href="#server-properties" class="headerlink" title="server.properties"></a>server.properties</h3><pre><code># the address the socket server listens onlisteners=PLAINTEXT://localhost:9092# zookeeper connection stringzookeeper.connect=localhost:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000</code></pre><h3 id="zookeeper-properties"><a href="#zookeeper-properties" class="headerlink" title="zookeeper.properties"></a>zookeeper.properties</h3><blockquote><p>启动 kafka 时，需要先启动 zookeeper 服务<br>可以启动 kafka 自带的 zookeeper，也可以启动外置的 zookeeper 服务</p></blockquote><pre><code># the directory where the snapshot is stored.dataDir=/usr/local/var/lib/zookeeper# the port at which the clients will connectclientPort=2181</code></pre><h2 id="启动和关闭服务"><a href="#启动和关闭服务" class="headerlink" title="启动和关闭服务"></a>启动和关闭服务</h2><ul><li>启动服务</li></ul><p>如果想以服务的方式启动，那么可以:</p><pre><code># 先安装 zookeeper（brew install zookeeper）$ brew services start zookeeper$ brew services start kafka</code></pre><p>如果只是临时启动，那么可以:</p><pre><code>$ bin/zookeeper-server-start.sh config/zookeeper.properties$ bin/kafka-server-start.sh config/server.properties$ jps -ml</code></pre><ul><li>关闭服务</li></ul><pre><code>$ bin/kafka-server-stop.sh stop$ bin/zookeeper-server-stop.sh stop$ jps -ml</code></pre><h2 id="常用操作命令"><a href="#常用操作命令" class="headerlink" title="常用操作命令"></a>常用操作命令</h2><ul><li>创建<code>topic</code></li></ul><pre><code>## 选项说明:##   --zookeeper zookeeper 服务 Host##   --topic 定义 topic 名称##   --replication-factor 定义副本数##   --partitions 定义分区数$ bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic test_topic --replication-factor 1 --partitions 3</code></pre><ul><li>删除<code>topic</code></li></ul><pre><code>## 选项说明:##   --zookeeper zookeeper 服务 Host##   --topic 定义 topic 名称$ bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic test_topic</code></pre><ul><li>发送消息</li></ul><pre><code>## 选项说明:##   --broker-list kafka 服务连接的节点，支持多节点##   --topic 定义 topic 名称$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test_topic</code></pre><ul><li>消费消息</li></ul><pre><code>## 选项说明:##   --bootstrap-server kafka 服务连接的节点，支持多节点##   --from-beginning  标识从头消费（offset=1）##   --topic 定义 topic 名称$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic test_topic</code></pre><ul><li>查看某个 <code>Topic</code> 的详情</li></ul><pre><code>## 选项说明:##   --zookeeper zookeeper 服务 Host##   --topic 定义 topic 名称$ bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test_topic</code></pre><ul><li>查看某个 <code>Topic</code> 的 <code>consumer_offsets</code> 详情 </li></ul><pre><code>## 选项说明:##   --zookeeper zookeeper 服务 Host##   --topic 定义 topic 名称bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic __consumer_offsets</code></pre><ul><li>验证消息生产成功</li></ul><pre><code>## 选项说明:##   --broker-list kafka 服务连接的节点，支持多节点##   --topic 定义 topic 名称##   --time -1表示显示获取当前offset最大值，-2表示offset的最小值$ bin/kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list localhost:9092 --topic test_topic --time -1</code></pre><ul><li>创建一个console consumer group</li></ul><pre><code>## 选项说明:##   --bootstrap-server kafka 服务连接的节点，支持多节点##   --from-beginning  标识从头消费（offset=1）##   --topic 定义 topic 名称##   --group 定义消费组名称$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test_topic --from-beginning --group new-consumer</code></pre><ul><li>获取该consumer group的group id</li></ul><pre><code>## 选项说明:##   --bootstrap-server kafka 服务连接的节点，支持多节点##   --list 显示消费组列表$ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase 安装和配置</title>
      <link href="/articles/hbase/an-zhuang-he-pei-zhi.html"/>
      <url>/articles/hbase/an-zhuang-he-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>系统环境：MacOS<br>Hadoop 版本：1.3.5</p></blockquote><h2 id="Homebrew安装HBase"><a href="#Homebrew安装HBase" class="headerlink" title="Homebrew安装HBase"></a>Homebrew安装HBase</h2><pre><code>$ brew info hbase$ brew install hbase$ cd /usr/local/Cellar/hbase/1.3.5/libexec</code></pre><h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><pre><code>$ vim ~/.zshrcexport HBASE_HOME="/usr/local/Cellar/hbase/1.3.5/libexec"  export PATH="$HBASE_HOME/bin:$PATH"$ source ~/.zshrc</code></pre><h2 id="配置文件设置"><a href="#配置文件设置" class="headerlink" title="配置文件设置"></a>配置文件设置</h2><blockquote><p>配置文件路径：/usr/local/Cellar/hbase/1.3.5/libexec/conf</p></blockquote><h3 id="hbase-env-sh"><a href="#hbase-env-sh" class="headerlink" title="hbase-env.sh"></a>hbase-env.sh</h3><pre><code>export HBASE_CLASSPATH=/usr/local/Celler/hadoop/3.2.1/libexec/etc/hadoopexport HBASE_MANAGES_ZK=trueexport HBASE_LOG_DIR=$HBASE_HOME/logsexport HBASE_REGIONSERVERS=$HBASE_HOME/conf/regionservers</code></pre><h3 id="hbase-site-xml"><a href="#hbase-site-xml" class="headerlink" title="hbase-site.xml"></a>hbase-site.xml</h3><pre><code>&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;hbase.rootdir&lt;/name&gt;        &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;        &lt;value&gt;2181&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;        &lt;value&gt;/usr/local/var/zookeeper&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.zookeeper.dns.interface&lt;/name&gt;        &lt;value&gt;lo0&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.regionserver.dns.interface&lt;/name&gt;        &lt;value&gt;lo0&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.master.dns.interface&lt;/name&gt;        &lt;value&gt;lo0&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;        &lt;value&gt;true&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;hbase.master.info.port&lt;/name&gt;        &lt;value&gt;16010&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;</code></pre><h3 id="regionservers"><a href="#regionservers" class="headerlink" title="regionservers"></a>regionservers</h3><pre><code>$ vim regionserverslocalhost</code></pre><h2 id="启动和关闭服务"><a href="#启动和关闭服务" class="headerlink" title="启动和关闭服务"></a>启动和关闭服务</h2><ul><li>启动服务</li></ul><pre><code>$ /usr/local/opt/hbase/bin/start-hbase.sh$ jps -ml86336 NodeManager85456 NameNode84672 HRegionServer85731 SecondaryNameNode85574 DataNode87355 HMaster87294 HQuorumPeer86222 ResourceManager</code></pre><ul><li>关闭服务</li></ul><pre><code>$ /usr/local/opt/hbase/bin/stop-hbase.sh$ jps -ml</code></pre><h2 id="访问监控页面"><a href="#访问监控页面" class="headerlink" title="访问监控页面"></a>访问监控页面</h2><p>HBase 默认提供了一个 webui 界面来监控它的健康状态，可以通过 <a href="http://localhost:16010/master-status" target="_blank" rel="noopener">http://localhost:16010/master-status</a> 访问。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PySpark之RDD入门</title>
      <link href="/articles/spark/pyspark-zhi-rdd-ru-men.html"/>
      <url>/articles/spark/pyspark-zhi-rdd-ru-men.html</url>
      
        <content type="html"><![CDATA[<h2 id="RDD的基本运算"><a href="#RDD的基本运算" class="headerlink" title="RDD的基本运算"></a>RDD的基本运算</h2><table><thead><tr><th align="left">RDD运算类型</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">转换（Transformation）</td><td align="left">转换运算将一个RDD转换为另一个RDD，但是由于RDD的lazy特性，转换运算不会立刻实际执行，它会等到执行到“动作”运算，才会实际执行。</td></tr><tr><td align="left">动作（Action）</td><td align="left">RDD执行动作运算之后，不会产生另一个RDD，它会产生数值、数组或写入文件系统；RDD执行动作运算后会立刻实际执行，并且连同之前的转换运算一起执行。</td></tr><tr><td align="left">持久化（Persistence）</td><td align="left">对于那些会重复使用的RDD， 可以将RDD持久化在内存中作为后续使用，以提高执行性能。</td></tr></tbody></table><h2 id="初始化-Spark-的上下环境"><a href="#初始化-Spark-的上下环境" class="headerlink" title="初始化 Spark 的上下环境"></a>初始化 Spark 的上下环境</h2><pre><code>from pyspark import SparkConf, SparkContextconf = SparkConf().setMaster("local").setAppName("My App")sc = SparkContext(conf = conf)</code></pre><h2 id="单个-RDD-“转换”运算"><a href="#单个-RDD-“转换”运算" class="headerlink" title="单个 RDD “转换”运算"></a>单个 RDD “转换”运算</h2><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个RDD</p></blockquote></li></ol><pre><code>intRDD = sc.parallelize([3,1,2,5,5])stringRDD = sc.parallelize(['Apple','Orange','Grape','Banana','Apple'])</code></pre><ol start="2"><li>collect()<blockquote><p>collect 可以把 RDD 类型的数据转换为 python 的数据类型</p></blockquote></li></ol><pre><code>print (intRDD.collect())[3, 1, 2, 5, 5]print (stringRDD.collect())['APPLE', 'Orange', 'Grape', 'Banana','Apple']</code></pre><ol start="3"><li>map()<blockquote><p>map 运算可以通过传入的函数，对RDD内每一个元素经过函数运算，并产生一个新的RDD；<br>下面的例子中，将intRDD中的每个元素加1之后返回，并转换为python数组；</p></blockquote></li></ol><pre><code>print (intRDD.map(lambda x:x+1).collect())[4, 2, 3, 6, 6]</code></pre><ol start="4"><li>filter()<blockquote><p>filter 运算可以用于对RDD内每一个元素进行筛选，并产生一个新的RDD；<br>下面的例子中，筛选intRDD中数字小于3的元素，筛选stringRDD中包含ra的字符串；</p></blockquote></li></ol><pre><code>print (intRDD.filter(lambda x: x&lt;3).collect())[1, 2]print (stringRDD.filter(lambda x:'ra' in x).collect())['Orange', 'Grape']</code></pre><ol start="5"><li>distinct()<blockquote><p>distinct 运算可以用于对RDD内重复的元素进行删除，并产生一个新的RDD；<br>下面的例子中，去除 intRDD 中的重复元素1；</p></blockquote></li></ol><pre><code>print (intRDD.distinct().collect())[1, 2, 3, 5]</code></pre><ol start="6"><li>randomSplit(weighs, *seed)<blockquote><p>randomSplit 运算将整个集合以随机数的方式按照比例分为多个RDD；<br>weights: 是一个数组,数组的长度即为划分成RDD的数量；<br>根据weight（权重值）将一个RDD划分成多个RDD,权重越高划分得到的元素较多的几率就越大；<br>seed: 是可选参数 ，作为random的种子；<br>下面的例子中，intRDD 按照0.4和0.6的比例将intRDD分为两个RDD；</p></blockquote></li></ol><pre><code>sRDD = intRDD.randomSplit([0.4,0.6])print (len(sRDD))2print (sRDD[0].collect())[3, 1]print (sRDD[1].collect())[2, 5, 5]</code></pre><ol start="7"><li>groupBy()<blockquote><p>groupBy 运算可以按照传入匿名函数的规则，将数据分为多个Array；<br>下面的例子中，将intRDD分为偶数和奇数：</p></blockquote></li></ol><pre><code>result = intRDD.groupBy(lambda x : x % 2).collect()print (sorted([(x, sorted(y)) for (x, y) in result]))[(0, [2]), (1, [1, 3, 5, 5])]</code></pre><h2 id="多个-RDD-“转换”运算"><a href="#多个-RDD-“转换”运算" class="headerlink" title="多个 RDD “转换”运算"></a>多个 RDD “转换”运算</h2><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个RDD</p></blockquote></li></ol><pre><code>intRDD1 = sc.parallelize([3,1,2,5,5])intRDD2 = sc.parallelize([5,6])intRDD3 = sc.parallelize([2,7])</code></pre><ol start="2"><li>union()<blockquote><p>使用union进行并集运算</p></blockquote></li></ol><pre><code>print (intRDD1.union(intRDD2).union(intRDD3).collect())[3, 1, 2, 5, 5, 5, 6, 2, 7] </code></pre><ol start="3"><li>intersection()<blockquote><p>使用intersection进行交集运算，取 RDD 的相同部分</p></blockquote></li></ol><pre><code>print (intRDD1.intersection(intRDD2).collect())[5] </code></pre><ol start="4"><li>subtract()<blockquote><p>使用subtract进行差集运算，取 RDD 的重复部分</p></blockquote></li></ol><pre><code>print (intRDD1.subtract(intRDD2).collect())[2, 1, 3]</code></pre><ol start="5"><li>cartesian()<blockquote><p>使用cartesian进行笛卡尔乘积运算</p></blockquote></li></ol><pre><code>print (intRDD1.cartesian(intRDD2).collect())[(3, 5), (3, 6), (1, 5), (1, 6), (2, 5), (2, 6), (5, 5), (5, 6), (5, 5), (5, 6)]</code></pre><h2 id="单个-RDD-“动作”运算"><a href="#单个-RDD-“动作”运算" class="headerlink" title="单个 RDD “动作”运算"></a>单个 RDD “动作”运算</h2><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个RDD</p></blockquote></li></ol><pre><code>intRDD = sc.parallelize([3,1,2,5,5])</code></pre><ol start="2"><li>读取元素<blockquote><p>可以使用下列命令读取RDD内的元素，这是Actions运算，所以会马上执行</p></blockquote></li></ol><pre><code># 取第一条数据print (intRDD.first())3# 取前两条数据print (intRDD.take(2))[3, 1]# 升序排列，并取前3条数据print (intRDD.takeOrdered(3))[1, 2, 3]# 降序排列，并取前3条数据print (intRDD.takeOrdered(3,lambda x:-x))[5, 5, 3]</code></pre><ol start="3"><li>统计功能<blockquote><p>可以将RDD内的元素进行统计运算</p></blockquote></li></ol><pre><code># 统计print (intRDD.stats())(count: 5, mean: 3.2, stdev: 1.6, max: 5, min: 1)# 最小值print (intRDD.min())1# 最大值print (intRDD.max())5# 标准差print (intRDD.stdev())1.6# 计数print (intRDD.count())5# 求和print (intRDD.sum())16# 平均print (intRDD.mean())3.2</code></pre><h2 id="单个-RDD-键值的“转换”运算"><a href="#单个-RDD-键值的“转换”运算" class="headerlink" title="单个 RDD 键值的“转换”运算"></a>单个 RDD 键值的“转换”运算</h2><blockquote><p>Spark RDD支持键值对运算，Key-Value运算是 mapreduce 运算的基础</p></blockquote><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个 RDD；<br>用元素类型为tuple元组的数组初始化 RDD；<br>每个tuple的第一个值将作为键，第二个元素将作为值；</p></blockquote></li></ol><pre><code>kvRDD1 = sc.parallelize([(3,4),(3,6),(5,6),(1,2)])</code></pre><ol start="2"><li>得到key和value值<blockquote><p>可以使用keys和values函数分别得到RDD的键数组和值数组</p></blockquote></li></ol><pre><code>print (kvRDD1.keys().collect())[3, 3, 5, 1]print (kvRDD1.values().collect())[4, 6, 6, 2]</code></pre><ol start="3"><li>筛选元素<blockquote><p>使用filter函数，可以按照键进行元素筛选，也可以通过值进行元素筛选；<br>注意：虽然RDD中是以键值对形式存在，但是本质上还是一个二元组，二元组的第一个值代表键，第二个值代表值；</p></blockquote></li></ol><pre><code># 筛选键的值小于5的数据print (kvRDD1.filter(lambda x:x[0] &lt; 5).collect())[(3, 4), (3, 6), (1, 2)]# 筛选值的值小于5的数据print (kvRDD1.filter(lambda x:x[1] &lt; 5).collect())[(3, 4), (1, 2)]</code></pre><ol start="4"><li>值运算<blockquote><p>可以使用mapValues方法处理value值；<br>下面的代码将value值进行了平方处理；</p></blockquote></li></ol><pre><code>print (kvRDD1.mapValues(lambda x:x**2).collect())[(3, 16), (3, 36), (5, 36), (1, 4)]</code></pre><ol start="5"><li>按照key排序<blockquote><p>可以使用sortByKey按照key进行排序，传入参数的默认值为true；<br>true 表示升序，false 表示倒序;</p></blockquote></li></ol><pre><code>print (kvRDD1.sortByKey().collect())[(1, 2), (3, 4), (3, 6), (5, 6)]print (kvRDD1.sortByKey(True).collect())[(1, 2), (3, 4), (3, 6), (5, 6)]print (kvRDD1.sortByKey(False).collect())[(5, 6), (3, 4), (3, 6), (1, 2)]</code></pre><ol start="6"><li>合并相同key值的数据<blockquote><p>可以使用reduceByKey函数对具有相同key值的数据进行合并；</p></blockquote></li></ol><pre><code>print (kvRDD1.reduceByKey(lambda x,y:x+y).collect())[(1, 2), (3, 10), (5, 6)]</code></pre><h2 id="多个-RDD-键值“转换”运算"><a href="#多个-RDD-键值“转换”运算" class="headerlink" title="多个 RDD 键值“转换”运算"></a>多个 RDD 键值“转换”运算</h2><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个 RDD；<br>用元素类型为tuple元组的数组初始化 RDD；<br>每个tuple的第一个值将作为键，第二个元素将作为值；</p></blockquote></li></ol><pre><code>kvRDD1 = sc.parallelize([(3,4),(3,6),(5,6),(1,2)])kvRDD2 = sc.parallelize([(3,8)])</code></pre><ol start="2"><li>内连接<blockquote><p>join运算可以将两个 RDD 按照相同的key值join起来；</p></blockquote></li></ol><pre><code>print (kvRDD1.join(kvRDD2).collect())[(3, (4, 8)), (3, (6, 8))] </code></pre><ol start="3"><li>左外连接<blockquote><p>leftOuterJoin运算可以将两个 RDD 左外连接起来；<br>如果kvRDD1的key值对应不到kvRDD2，就会显示None</p></blockquote></li></ol><pre><code>print (kvRDD1.leftOuterJoin(kvRDD2).collect())[(1, (2, None)), (3, (4, 8)), (3, (6, 8)), (5, (6, None))]</code></pre><ol start="4"><li>右外连接<blockquote><p>rightOuterJoin运算可以将两个 RDD 右外连接起来；<br>如果kvRDD2的key值对应不到kvRDD1，就会显示None</p></blockquote></li></ol><pre><code>print (kvRDD1.rightOuterJoin(kvRDD2).collect())[(3, (4, 8)), (3, (6, 8))]</code></pre><ol start="5"><li>删除相同key值数据<blockquote><p>使用subtractByKey运算会删除相同key值得数据：</p></blockquote></li></ol><pre><code>print (kvRDD1.subtractByKey(kvRDD2).collect())[(1, 2), (5, 6)] </code></pre><h2 id="单个-RDD-键值“动作”运算"><a href="#单个-RDD-键值“动作”运算" class="headerlink" title="单个 RDD 键值“动作”运算"></a>单个 RDD 键值“动作”运算</h2><ol><li>创建RDD<blockquote><p>使用parallelize方法创建一个 RDD；<br>用元素类型为tuple元组的数组初始化 RDD；<br>每个tuple的第一个值将作为键，第二个元素将作为值；</p></blockquote></li></ol><pre><code>kvRDD1 = sc.parallelize([(3,4),(3,6),(5,6),(1,2)])</code></pre><ol start="2"><li>读取数据<blockquote><p>可以使用下面的几种方式读取RDD的数据：</p></blockquote></li></ol><pre><code># 读取第一条数据print (kvRDD1.first())(3, 4)# 读取前两条数据print (kvRDD1.take(2))[(3, 4), (3, 6)]# 读取第一条数据的key值print (kvRDD1.first()[0])3# 读取第一条数据的value值print (kvRDD1.first()[1])4</code></pre><ol start="3"><li>按key值统计：<blockquote><p>使用countByKey函数可以统计各个key值对应的数据的条数；</p></blockquote></li></ol><pre><code>print (kvRDD1.countByKey().collect())defaultdict(&lt;type 'int'&gt;, {1: 1, 3: 2, 5: 1})</code></pre><ol start="4"><li>查找运算<blockquote><p>使用lookup函数可以根据输入的key值来查找对应的Value值：</p></blockquote></li></ol><pre><code>print (kvRDD1.lookup(3))[4, 6]</code></pre><h2 id="持久化操作"><a href="#持久化操作" class="headerlink" title="持久化操作"></a>持久化操作</h2><blockquote><p>spark RDD的持久化机制，可以将需要重复运算的RDD存储在内存中，以便大幅提升运算效率</p></blockquote><ol><li>persist()<blockquote><p>使用persist函数对RDD进行持久化</p></blockquote></li></ol><pre><code>from pyspark.storagelevel import StorageLevelkvRDD1.persist(StorageLevel.MEMORY_ONLY)</code></pre><p>在持久化的同时可以指定持久化存储等级：</p><table><thead><tr><th align="left">等级</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">MEMORY_ONLY</td><td align="left">以反序列化的JAVA对象的方式存储在JVM中. 如果内存不够， RDD的一些分区将不会被缓存， 这样当再次需要这些分区的时候，将会重新计算。这是默认的级别。</td></tr><tr><td align="left">MEMORY_AND_DISK</td><td align="left">以反序列化的JAVA对象的方式存储在JVM中. 如果内存不够， RDD的一些分区将将会缓存在磁盘上，再次需要的时候从磁盘读取。</td></tr><tr><td align="left">MEMORY_ONLY_SER</td><td align="left">以序列化JAVA对象的方式存储 (每个分区一个字节数组). 相比于反序列化的方式,这样更高效的利用空间， 尤其是使用快速序列化时。但是读取是CPU操作很密集。</td></tr><tr><td align="left">MEMORY_AND_DISK_SER</td><td align="left">与MEMORY_ONLY_SER相似, 区别是但内存不足时，存储在磁盘上而不是每次重新计算。</td></tr><tr><td align="left">DISK_ONLY</td><td align="left">只存储RDD在磁盘</td></tr><tr><td align="left">MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc.</td><td align="left">与上面的级别相同，只不过每个分区的副本只存储在两个集群节点上。</td></tr><tr><td align="left">OFF_HEAP (experimental)</td><td align="left">将RDD以序列化的方式存储在 Tachyon. 与 MEMORY_ONLY_SER相比, OFF_HEAP减少了垃圾回收。允许执行体更小通过共享一个内存池。因此对于拥有较大堆内存和高并发的环境有较大的吸引力。更重要的是，因为RDD存储在Tachyon上，执行体的崩溃不会造成缓存的丢失。在这种模式下.Tachyon中的内存是可丢弃的，这样 Tachyon 对于从内存中挤出的块不会试图重建它。如果你打算使用Tachyon作为堆缓存，Spark提供了与Tachyon相兼容的版本。</td></tr></tbody></table><ol start="2"><li>unpersist()<blockquote><p>使用unpersist函数对RDD进行取消持久化；</p></blockquote></li></ol><pre><code>kvRDD1.unpersist()</code></pre><h2 id="整理回顾"><a href="#整理回顾" class="headerlink" title="整理回顾"></a>整理回顾</h2><p>想要了解更多，可以参照官网给出的官方文档：<a href="http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD</a></p><p>今天主要介绍了两种RDD，基本的RDD和Key-Value形式的RDD，介绍了他们的几种“转换”运算和“动作”运算，整理如下：</p><table><thead><tr><th align="left">RDD运算</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">基本RDD“转换”运算</td><td align="left">map（对各数据进行转换），filter（过滤符合条件的数据），distinct（去重运算），randomSplit（根据指定的比例随机分为N各RDD），groupBy（根据条件对数据进行分组），union（两个RDD取并集），intersection（两个RDD取交集），subtract（两个RDD取差集），cartesian（两个RDD进行笛卡尔积运算）</td></tr><tr><td align="left">基本RDD“动作”运算</td><td align="left">first（取第一条数据），take（取前几条数据），takeOrdered（排序后取前N条数据），统计函数</td></tr><tr><td align="left">Key-Value形式 RDD“转换”运算</td><td align="left">filter（过滤符合条件的数据），mapValues（对value值进行转换），sortByKey（根据key值进行排序），reduceByKey（合并相同key值的数据），join（内连接两个KDD），leftOuterJoin（左外连接两个KDD），rightOuterJoin（右外连接两个RDD），subtractByKey（相当于key值得差集运算）</td></tr><tr><td align="left">Key-Value形式 RDD“动作”运算</td><td align="left">first（取第一条数据），take（取前几条数据），countByKey（根据key值分组统计），lookup（根据key值查找value值）</td></tr><tr><td align="left">RDD持久化</td><td align="left">persist用于对RDD进行持久化，unpersist取消RDD的持久化，注意持久化的存储等级</td></tr></tbody></table><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> PySpark </tag>
            
            <tag> RDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark 安装和配置</title>
      <link href="/articles/spark/an-zhuang-he-pei-zhi.html"/>
      <url>/articles/spark/an-zhuang-he-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>系统环境：MacOS<br>Hadoop 版本：2.4.4</p></blockquote><h2 id="Homebrew安装Spark"><a href="#Homebrew安装Spark" class="headerlink" title="Homebrew安装Spark"></a>Homebrew安装Spark</h2><pre><code>$ brew install apache-spark$ cd /usr/local/Cellar/apache-spark/2.4.4/libexec</code></pre><h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><pre><code>$ vim ~/.zshrcexport SPARK_HOME="/usr/local/Cellar/apache-spark/2.4.4/libexec"  export PATH="$SPARK_HOME/bin:$PATH"$ source ~/.zshrc</code></pre><h2 id="检测是否安装成功"><a href="#检测是否安装成功" class="headerlink" title="检测是否安装成功"></a>检测是否安装成功</h2><blockquote><p>在spark-shell中完成单词统计</p></blockquote><pre><code>$ spark-shell......scala&gt; val file = sc.textFile("/usr/local/Cellar/apache-spark/2.4.4/README.md")file: org.apache.spark.rdd.RDD[String] = /usr/local/Cellar/apache-spark/2.4.4/README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:24# 以空格为拆分标志，将文件中的每一行分割为多个单词scala&gt; val words = file.flatMap(line =&gt; line.split(" "))words: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at flatMap at &lt;console&gt;:25# 对每一个单词进行计数scala&gt; val wordNumber = words.map(w =&gt; (w, 1))wordNumber: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[3] at map at &lt;console&gt;:25# 将单词进行分类合并，计算每个单词总的出现次数scala&gt; val wordCounts = wordNumber.reduceByKey(_+_)wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[4] at reduceByKey at &lt;console&gt;:25# 将所有单词及其出现次数打印出来scala&gt; wordsCounts.foreach(println)......</code></pre><h2 id="pyspark-启动Spark"><a href="#pyspark-启动Spark" class="headerlink" title="pyspark 启动Spark"></a>pyspark 启动Spark</h2><ul><li>环境变量设置</li></ul><pre><code>$ vim ~/.zshrc# 设置 python 版本，默认是2.7.xexport PYSPARK_PYTHON="python3"$ source ~/.zshrc</code></pre><ul><li>脚本的执行权限设置</li></ul><pre><code>$ cd /usr/local/Cellar/apache-spark/2.4.4/libexec/bin$ chmod a+x *$ cd /usr/local/Cellar/apache-spark/2.4.4/libexec/sbin$ chmod a+x *</code></pre><ul><li>启动 spark</li></ul><pre><code>$ pyspark......Using Python version 3.7.4 (default, Jul  9 2019 18:13:23)SparkSession available as 'spark'.# 初始化&gt;&gt;&gt; from pyspark import SparkConf, SparkContext&gt;&gt;&gt; conf = SparkConf().setMaster("local").setAppName("My App")&gt;&gt;&gt; sc = SparkContext(conf = conf)# 创建RDD&gt;&gt;&gt; intRDD = sc.parallelize([3,1,2,5,5])# collect（RDD -&gt; python 数据类型）&gt;&gt;&gt; print (intRDD.collect())[3, 1, 2, 5, 5]</code></pre><h2 id="启动和关闭"><a href="#启动和关闭" class="headerlink" title="启动和关闭"></a>启动和关闭</h2><ul><li>启动服务</li></ul><pre><code>$ /usr/local/opt/apache-spark/libexec/sbin/start-master.shstarting org.apache.spark.deploy.master.Master, logging to /usr/local/Cellar/apache-spark/2.4.4/libexec/logs/spark-bigo-org.apache.spark.deploy.master.Master-1-bigodeMBP.lan.out$ jps -lm</code></pre><ul><li>关闭服务</li></ul><pre><code>$ /usr/local/opt/apache-spark/libexec/sbin/stop-master.shstopping org.apache.spark.deploy.master.Master$ jps -lm</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive 安装和配置</title>
      <link href="/articles/hive/an-zhuang-he-pei-zhi.html"/>
      <url>/articles/hive/an-zhuang-he-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>系统环境：MacOS<br>Hadoop 版本：3.1.2</p></blockquote><h2 id="Homebrew安装Hive"><a href="#Homebrew安装Hive" class="headerlink" title="Homebrew安装Hive"></a>Homebrew安装Hive</h2><pre><code>$ brew install hive$ cd /usr/local/Celler/hive/3.1.2/libexec</code></pre><h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><pre><code>$ vim ~/.zshrcexport HIVE_HOME="/usr/local/Cellar/hive/3.1.2/libexec"  export PATH="$HIVE_HOME/bin:$PATH"$ source ~/.zshrc</code></pre><h2 id="配置文件设置"><a href="#配置文件设置" class="headerlink" title="配置文件设置"></a>配置文件设置</h2><blockquote><p>在 <strong>libexec/conf</strong> 下提供了一些 <strong>.template</strong> 模板，拷贝文件并去掉 <strong>.template</strong> 后缀即可</p></blockquote><h3 id="修改日志文件"><a href="#修改日志文件" class="headerlink" title="修改日志文件"></a>修改日志文件</h3><pre><code>$ cp hive-log4j2.properties.template hive-log4j2.properties$ cp beeline-log4j2.properties.template beeline-log4j2.properties$ cp hive-exec-log4j2.properties.template hive-exec-log4j2.properties$ cp llap-daemon-log4j2.properties.template llap-daemon-log4j2.properties$ cp llap-cli-log4j2.properties.template llap-cli-log4j2.properties# 更改 hive log 目录，默认为：/tmp$ vim hive-log4j2.propertiesproperty.hive.log.dir = /usr/local/Cellar/hive/3.1.2/libexec/logs</code></pre><h3 id="hive-site-xml-配置"><a href="#hive-site-xml-配置" class="headerlink" title="hive-site.xml 配置"></a>hive-site.xml 配置</h3><blockquote><p>将 <strong>hive-default.xml.template</strong> 文件复制一份，并且改名为 <strong>hive-site.xml</strong></p></blockquote><pre><code>$ cp hive-default.xml.template hive-site.xml</code></pre><ul><li>在 hdfs 创建 hive 目录（在hive-site.xml中有这样的配置）<pre><code>&lt;property&gt;  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;  &lt;description&gt;Hive 默认的数据文件存储路径，通常为 HDFS 可写的路径&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;  &lt;value&gt;/tmp/hive&lt;/value&gt;  &lt;description&gt;HDFS路径，用于存储不同 map/reduce 阶段的执行计划和这些阶段的中间输出结果&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.cli.print.header&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.cli.print.current.db&lt;/name&gt;  &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;</code></pre></li></ul><p>在hdfs中新建目录 <strong>/user/hive/warehouse</strong> 和 <strong>/tmp/hive</strong>，赋予读写权限</p><pre><code>$ hadoop fs -mkdir -p /user/hive/warehouse$ hadoop fs -chmod 777 /user/hive/warehouse$ hadoop fs -mkdir -p /tmp/hive$ hadoop fs -chmod 777 /tmp/hive</code></pre><ul><li><p>修改 hive 临时目录</p><blockquote><p>将 ${system:java.io.tmpdir} 替换为本地hive的临时目录(/usr/local/Cellar/hive/3.1.2/tmp/hive)，并赋予读写权限；<br>将 ${system:user.name} 替换为root；</p></blockquote><pre><code>&lt;property&gt;  &lt;name&gt;hive.querylog.location&lt;/name&gt;  &lt;value&gt;${system:java.io.tmpdir}/${system:user.name}&lt;/value&gt;  &lt;description&gt;Location of Hive run time structured log file&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;  &lt;value&gt;${system:java.io.tmpdir}/${system:user.name}/operation_logs&lt;/value&gt;  &lt;description&gt;Top level directory where operation logs are stored if logging functionality is enabled&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;  &lt;value&gt;${system:java.io.tmpdir}/${system:user.name}&lt;/value&gt;  &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;  &lt;value&gt;${system:java.io.tmpdir}/${hive.session.id}_resources&lt;/value&gt;  &lt;description&gt;Temporary local directory for added resources in the remote file system.&lt;/description&gt;&lt;/property&gt;</code></pre></li><li><p>修改数据库相关的配置</p><blockquote><p>javax.jdo.option.ConnectionURL    将对应的value修改为MySQL的地址<br>javax.jdo.option.ConnectionDriverName    将对应的value修改为MySQL驱动类路径<br>javax.jdo.option.ConnectionUserName    将对应的value修改为MySQL数据库登录名<br>javax.jdo.option.ConnectionPassword    将对应的value修改为MySQL数据库的登录密码<br>hive.metastore.schema.verification    将对应的value修改为false</p></blockquote></li></ul><pre><code>&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;    &lt;value&gt;jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;    &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;    &lt;value&gt;&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;    &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;</code></pre><p>下载MySQL驱动包到lib目录<br><a href="https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.48.tar.gz" target="_blank" rel="noopener">https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.48.tar.gz</a></p><ul><li>WebUI<blockquote><p>Hive从2.0版本开始，为HiveServer2提供了一个简单的WEB UI界面，界面中可以直观的看到当前链接的会话、历史日志、配置参数以及度量信息。</p></blockquote></li></ul><pre><code>&lt;property&gt;    &lt;name&gt;hive.server2.webui.host&lt;/name&gt;    &lt;value&gt;127.0.0.1&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;hive.server2.webui.port&lt;/name&gt;    &lt;value&gt;10002&lt;/value&gt;&lt;/property&gt;</code></pre><p>需要重启HiveServer2</p><pre><code>$ hive --service hiveserver2 &amp;</code></pre><h3 id="hive-env-sh-配置"><a href="#hive-env-sh-配置" class="headerlink" title="hive-env.sh 配置"></a>hive-env.sh 配置</h3><blockquote><p>将 <strong>hive-env.sh.template</strong> 文件复制一份，并且改名为 <strong>hive-env.sh</strong> 文件</p></blockquote><pre><code>$ cp hive-env.sh.template hive-env.sh$ vim hive-env.shexport HADOOP_HOME=/usr/local/Cellar/hadoop/3.2.1/libexecexport HIVE_CONF_DIR=/usr/local/Cellar/hive/3.1.2/confexport HIVE_AUX_JARS_PATH=/usr/local/Cellar/hive/3.1.2/lib</code></pre><h2 id="启动和测试"><a href="#启动和测试" class="headerlink" title="启动和测试"></a>启动和测试</h2><h3 id="对MySQL数据库进行初始化"><a href="#对MySQL数据库进行初始化" class="headerlink" title="对MySQL数据库进行初始化"></a>对MySQL数据库进行初始化</h3><blockquote><p>执行成功后，hive数据库里已经有一堆表创建好了</p></blockquote><pre><code>$ /usr/local/opt/hive/bin/schematool -initSchema -dbType mysql</code></pre><h3 id="启动hive"><a href="#启动hive" class="headerlink" title="启动hive"></a>启动hive</h3><pre><code>$ /usr/local/opt/hive/bin/hiveor$ hive</code></pre><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><pre><code># 进入hive命令行&gt; show functions;</code></pre><h3 id="新建表以及导入数据的测试"><a href="#新建表以及导入数据的测试" class="headerlink" title="新建表以及导入数据的测试"></a>新建表以及导入数据的测试</h3><pre><code>&gt; create database db_hive_edu;&gt; use db_hive_edu;&gt; create table student(id int,name string) row format delimited fields terminated by '\t';# 将文件数据写入表中$ touch /opt/hive/student.txt001 zhangsan002 lisi003 wangwu004 zhaoliu005 chenqi# 载入表&gt; load data local inpath '/opt/hive/student.txt' into table db_hive_edu.student;# 测试&gt; select * from student;OK001 zhangsan002 lisi003 wangwu004 zhaoliu005 chenqi# 查看hdfs上数据/user/hive/warehouse/db_hive_edu.db/student# 在MySQL中查看$ SELECT * FROM hive.TBLS;</code></pre><h3 id="错误和解决"><a href="#错误和解决" class="headerlink" title="错误和解决"></a>错误和解决</h3><ol><li>WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable</li></ol><p>解决方案：实际上其实这个警告可以不予理会。</p><ol start="2"><li>There are 2 datanode(s) running and 2 node(s) areexcluded in this operation.</li></ol><p>发生原因：hadoop中的datanode有问题，没法写入数据。</p><p>解决方案：检查hadoop是否正常运行。</p><ol start="3"><li>Class path contains multiple SLF4J bindings.<pre><code>SLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/Cellar/hive/3.1.2/libexec/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/Cellar/hadoop/3.2.1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</code></pre></li></ol><p>发生原因：hive 和 hadoop 依赖的 log4j-slf4j 包版本不一致，造成冲突</p><p>解决方案：删除 hive lib 目录下的 log4j-slf4j 包；</p><pre><code>$ rm /usr/local/Cellar/hive/3.1.2/libexec/lib/log4j-slf4j-impl-2.10.0.jar</code></pre><ol start="4"><li>Exception in thread “main” java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument<pre><code>Exception in thread "main" java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V at org.apache.hadoop.conf.Configuration.set(Configuration.java:1357) at org.apache.hadoop.conf.Configuration.set(Configuration.java:1338) at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:536) at org.apache.hadoop.mapred.JobConf.setJarByClass(JobConf.java:554) at org.apache.hadoop.mapred.JobConf.&lt;init&gt;(JobConf.java:448) at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5141) at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104) at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96) at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:323) at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</code></pre></li></ol><p>发生原因：hive内依赖的guava.jar和hadoop内的版本不一致造成的。</p><p>解决方案：</p><ul><li>查看hadoop安装目录下share/hadoop/common/lib内guava.jar版本；</li><li>查看hive安装目录下lib内guava.jar的版本；</li><li>如果两者不一致，删除版本低的，并拷贝高版本的到相应的目录下；<pre><code>$ rm /usr/local/Cellar/hive/3.1.2/libexec/lib/guava-19.0.jar$ cp /usr/local/Cellar/hadoop/3.2.1/libexec/share/hadoop/common/lib/guava-27.0-jre.jar /usr/local/Cellar/hive/3.1.2/libexec/lib/</code></pre></li></ul><ol start="5"><li>com.ctc.wstx.exc.WstxParsingException: Illegal character entity: expansion character<pre><code>Exception in thread "main" java.lang.RuntimeException: com.ctc.wstx.exc.WstxParsingException: Illegal character entity: expansion character (code 0x8at [row,col,system-id]: [3215,96,"file:/usr/local/Cellar/hive/3.1.2/libexec/conf/hive-site.xml"] at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3024) at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2973) at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2848) at org.apache.hadoop.conf.Configuration.get(Configuration.java:1460) at org.apache.hadoop.hive.conf.HiveConf.getVar(HiveConf.java:4996) at org.apache.hadoop.hive.conf.HiveConf.getVar(HiveConf.java:5069) at org.apache.hadoop.hive.conf.HiveConf.initialize(HiveConf.java:5156) at org.apache.hadoop.hive.conf.HiveConf.&lt;init&gt;(HiveConf.java:5104) at org.apache.hive.beeline.HiveSchemaTool.&lt;init&gt;(HiveSchemaTool.java:96) at org.apache.hive.beeline.HiveSchemaTool.main(HiveSchemaTool.java:1473) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.apache.hadoop.util.RunJar.run(RunJar.java:323) at org.apache.hadoop.util.RunJar.main(RunJar.java:236)</code></pre></li></ol><p>发生原因：hive-site.xml包括无效字符</p><pre><code>&lt;property&gt;    &lt;name&gt;hive.txn.xlock.iow&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;    &lt;description&gt;      Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive locks for&amp;...8;transactional tables.  This ensures that inserts (w/o overwrite) running concurrently      are not hidden by the INSERT OVERWRITE.    &lt;/description&gt;&lt;/property</code></pre><p>解决方案：去掉无效字符</p><pre><code>&lt;property&gt;    &lt;name&gt;hive.txn.xlock.iow&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;    &lt;description&gt;      Ensures commands with OVERWRITE (such as INSERT OVERWRITE) acquire Exclusive locks for;transactional tables.  This ensures that inserts (w/o overwrite) running concurrently      are not hidden by the INSERT OVERWRITE.    &lt;/description&gt;&lt;/property&gt;</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop 安装和配置</title>
      <link href="/articles/hadoop/an-zhuang-he-pei-zhi.html"/>
      <url>/articles/hadoop/an-zhuang-he-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>系统环境：MacOS<br>Hadoop 版本：3.2.1</p></blockquote><h2 id="打开本地电脑的ssh登录方式"><a href="#打开本地电脑的ssh登录方式" class="headerlink" title="打开本地电脑的ssh登录方式"></a>打开本地电脑的ssh登录方式</h2><pre><code># 生成公钥$ ssh-keygen -t rsa -C "your.email@example.com" -b 4096# 一路默认# 拷贝$ cat ~/.ssh/id_rsa.pub# 拷贝至电脑信任列表$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></pre><p>系统设置(System Preferences) -&gt; 共享(sharing) -&gt; 勾选☑️远程登录(Remote Login)</p><p>最后可以在终端(Terminal)测试下</p><pre><code>$ ssh localhost</code></pre><h2 id="使用Homebrew安装Hadoop"><a href="#使用Homebrew安装Hadoop" class="headerlink" title="使用Homebrew安装Hadoop"></a>使用Homebrew安装Hadoop</h2><pre><code>$ brew install hadoop$ cd /usr/local/Celler/hadoop/3.2.1/libexec</code></pre><h2 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h2><blockquote><p>Hadoop有三种安装模式：单机模式，伪分布式模式，分布式模式。Homebrew生成的默认是单机模式，下面只涉及伪分布式配置。<br>配置文件路径：/usr/local/Celler/hadoop/3.2.1/libexec/etc/hadoop</p></blockquote><ul><li>修改core-site.xml</li></ul><pre><code>&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt;    &lt;description&gt;A base for other temporary directories&lt;/description&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;fs.default.name&lt;/name&gt;    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><ul><li>修改mapred-site.xml</li></ul><pre><code>&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;mapred.job.tracker&lt;/name&gt;    &lt;value&gt;localhost:9010&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;    &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;mapreduce.map.env&lt;/name&gt;    &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;    &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><ul><li>修改hdfs-site.xml</li></ul><pre><code>&lt;configuration&gt;  &lt;!-- 伪分布式配置 --&gt;  &lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;1&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><ul><li>yarn-site.xml</li></ul><pre><code>&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><ul><li>修改hadoop-env.sh</li></ul><pre><code>export JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home"export HADOOP_OPTS="-Djava.net.preferIPv4Stack=true -Dsun.security.krb5.debug=true -Dsun.security.spnego.debug"export HADOOP_OS_TYPE=${HADOOP_OS_TYPE:-$(uname -s)}case ${HADOOP_OS_TYPE} in  Darwin*)    export HADOOP_OPTS="${HADOOP_OPTS} -Djava.security.krb5.realm= "    export HADOOP_OPTS="${HADOOP_OPTS} -Djava.security.krb5.kdc= "    export HADOOP_OPTS="${HADOOP_OPTS} -Djava.security.krb5.conf= "    export YARN_HOME=$HADOOP_HOME  ;;esac</code></pre><h2 id="初始化NameNode"><a href="#初始化NameNode" class="headerlink" title="初始化NameNode"></a>初始化NameNode</h2><blockquote><p>注意⚠️建议不要往~/.bash_profile里PATH变量添加hadoop相关的路径，楼主遇到过坑，每次在终端打开/usr/local/Celler/hadoop/3.2.1/</p></blockquote><pre><code>$ ./bin/hdfs namenode -format </code></pre><blockquote><p>只需要第一次,玩崩了也可以再执行下</p></blockquote><h2 id="启动和关闭"><a href="#启动和关闭" class="headerlink" title="启动和关闭"></a>启动和关闭</h2><blockquote><p>可以在终端任意位置使用jps查看启动的java应用程序，理论启动完毕其中会包括：NameNode, DataNode, NodeManager, ResoureManager四个java程序</p></blockquote><ul><li>启动NameNode和DataNode</li></ul><pre><code>$ /usr/local/opt/hadoop/libexec/sbin/start-dfs.sh$ jps -lm</code></pre><p>启动完毕即可登录：<a href="http://localhost:9870" target="_blank" rel="noopener">http://localhost:9870</a></p><ul><li>启动Yarn(ResourceManager和NodeManager)</li></ul><pre><code>$ /usr/local/opt/hadoop/libexec/sbin/start-yarn.sh$ jps -lm</code></pre><p>启动完毕即可登录：<a href="http://localhost:8088" target="_blank" rel="noopener">http://localhost:8088</a></p><ul><li>关闭NameNode和DataNode</li></ul><pre><code>$ /usr/local/opt/hadoop/libexec/sbin/stop-dfs.sh$ jps -lm</code></pre><ul><li>关闭Yarn(ResourceManager和NodeManager)</li></ul><pre><code>$ /usr/local/opt/hadoop/libexec/sbin/stop-yarn.sh$ jps -lm</code></pre><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><pre><code># 打开文件执行位置$ cd /usr/local/Cellar/hadoop/3.2.1/bin# 查看已启动内容$ jps# 查看信息$ hdfs dfsadmin -report# 创建文件夹$ hdfs dfs -mkdir /test# 查看文件夹下文件$ hdfs dfs -ls /# 查看所有命令$ hdfs dfs -help# 查看文件内容$ hdfs dfs -cat /test/mk.txt# 拷贝至hdfs$ hdfs dfs -copyFromLocal /Users/goddy/repo/hadoop/hdfs-file/mk.txt /test/# 拷贝至本地$ hdfs dfs -copyToLocal /test/mk.txt /Users/goddy/repo/hadoop/hdfs-file/mk2.txt# 更改文件权限$ hdfs dfs -chmod 777 /test/mk.txt备注：hdfs dfs 可以替换为：hadoop fs</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Homebrew 镜像源</title>
      <link href="/articles/homebrew-jing-xiang-yuan.html"/>
      <url>/articles/homebrew-jing-xiang-yuan.html</url>
      
        <content type="html"><![CDATA[<h2 id="镜像源"><a href="#镜像源" class="headerlink" title="镜像源"></a>镜像源</h2><ul><li>官方镜像源</li></ul><pre><code>https://github.com/Homebrew/brew.githttps://github.com/Homebrew/homebrew-core.git</code></pre><ul><li>中科大源</li></ul><pre><code>https://mirrors.ustc.edu.cn/brew.githttps://mirrors.ustc.edu.cn/homebrew-core.githttps://mirrors.ustc.edu.cn/homebrew-bottles</code></pre><ul><li>清华源</li></ul><pre><code>https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.githttps://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.githttps://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles</code></pre><h2 id="镜像源设置"><a href="#镜像源设置" class="headerlink" title="镜像源设置"></a>镜像源设置</h2><ul><li>替换 brew.git</li></ul><pre><code>$ cd "$(brew --repo)”$ git remote set-url origin https://mirrors.ustc.edu.cn/brew.gitor$ git -C "$(brew --repo)" remote set-url origin https://mirrors.ustc.edu.cn/brew.git</code></pre><ul><li>替换 homebrew-core.git</li></ul><pre><code>$ cd "$(brew --repo homebrew/core)”$ git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.gitor$ git -C "$(brew --repo homebrew/core)" remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git</code></pre><ul><li>执行更新</li></ul><pre><code>$ brew update</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MacOS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> Homebrew </tag>
            
            <tag> brew </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>lrzsz 安装和配置</title>
      <link href="/articles/lrzsz-an-zhuang-he-pei-zhi.html"/>
      <url>/articles/lrzsz-an-zhuang-he-pei-zhi.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>MacOS 自带的命令终端不支持使用 rz 和 sz 命令进行文件上传和下载。<br>可以安装另一种终端 iTerm2，然后对 iTerm2 进行扩展安装 lrzsz，这样 Mac 就可以使用 rz 和 sz 命令进行文件传输了。</p></blockquote><h2 id="远程服务器安装"><a href="#远程服务器安装" class="headerlink" title="远程服务器安装"></a>远程服务器安装</h2><p>在 centOs下，可以用自带的包管理工具进行下载，命令如下:</p><pre><code>$ yum -y install lrzsz</code></pre><h2 id="本地-MacOS-安装和配置"><a href="#本地-MacOS-安装和配置" class="headerlink" title="本地 MacOS 安装和配置"></a>本地 MacOS 安装和配置</h2><ol><li>Homebrew 安装 lrzsz</li></ol><pre><code>$ brew install lrzsz</code></pre><ol start="2"><li>下载安装 iterm2 send、recv <blockquote><p><a href="https://pan.baidu.com/s/1IVr1wCeSw1NPMPlZRg9Q5w" target="_blank" rel="noopener">下载链接</a> (提取码: h467)</p></blockquote></li></ol><pre><code>$ cp iterm2-send-zmodem.sh /usr/local/bin$ cp iterm2-recv-zmodem.sh /usr/local/bin# 添加可执行权限$ chmode +x /usr/local/bin/iterm2-send-zmodem.sh$ chmode +x /usr/local/bin/iterm2-recv-zmodem.sh</code></pre><ol start="3"><li>设置 iterm2，按 command+, 组合键，打开 iTerm2设置界面，切换到 Profiles-&gt; Default -&gt; Advanced，点击“Edit”</li></ol><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/lrzsz-01.png" alt=""></p><ol start="4"><li>在弹出的界面点 “+” 新增两项参数，完成后，点击“Close”关闭弹窗</li></ol><table><thead><tr><th align="left">Regular Expression</th><th align="left">Action</th><th align="left">Action</th></tr></thead><tbody><tr><td align="left">**B010</td><td align="left">Run Silent Coprocess</td><td align="left">/usr/local/bin/iterm2-send-zmodem.sh</td></tr><tr><td align="left">**B00000000000000</td><td align="left">Run Silent Coprocess</td><td align="left">/usr/local/bin/iterm2-recv-zmodem.sh</td></tr></tbody></table><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/lrzsz-02.png" alt=""></p><ol start="5"><li>重启iterm2</li></ol><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><pre><code># 链接远程linux（注意上传文件路径不能包含中文）$ rz # 上传文件$ sz # 下载文件</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> MacOS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MacOS </tag>
            
            <tag> lrzsz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java8 - 函数式编程之Stream</title>
      <link href="/articles/java/han-shu-shi-bian-cheng-zhi-stream.html"/>
      <url>/articles/java/han-shu-shi-bian-cheng-zhi-stream.html</url>
      
        <content type="html"><![CDATA[<h2 id="什么是Stream"><a href="#什么是Stream" class="headerlink" title="什么是Stream"></a>什么是Stream</h2><p>Stream API 借助于 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。</p><p>流主要有三部分构成：获取一个数据源（source）→ 数据转换 → 执行操作获取想要的结果。每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道。</p><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-01.jpg" alt=""></p><h2 id="Stream的特点"><a href="#Stream的特点" class="headerlink" title="Stream的特点"></a>Stream的特点</h2><ul><li><p><strong>无存储性</strong></p><p>流不是存储元素的数据结构；相反，它需要从数据结构，数组，生成器函数或IO管道中获取数据并通过流水线地(计算)操作对这些数据进行转换。</p></li><li><p><strong>函数式编程</strong></p><p>Stream上操作会产生一个新结果，而不会去修改原始数据。比如filter过滤操作它只会根据原始集合中将未被过滤掉的元素生成一个新的Stream，而不是真的去删除集合中的元素。</p></li><li><p><strong>惰性求值</strong></p><p>很多Stream操作(如filter,map,distinct等)都是惰性实现，这样做为了优化程序的计算。比如说，要从一串数字中找到第一个能被10整除的数，程序并不需要对这一串数字中的每个数字进行测试。流操作分为两种：中间操作(返回值仍为Stream，仍可执行操作)，终断操作(结束Stream操作)。中间操作都是惰性操作。</p></li><li><p><strong>无限数据处理</strong></p><p>集合的大小是有限的，但是流可以对无限的数据执行操作。比如可以使用limit或findFirst这样的操作让Stream操作在有限的时间内结束。</p></li><li><p><strong>一次性消费</strong></p><p>流只能使用(“消费”)一次，一旦调用终断操作，流就不能再次使用，必须重新创建一个流。就像迭代器一样，遍历一遍后，想要再次遍历需要重新创建一个迭代器。</p></li></ul><h2 id="Stream的源的构建"><a href="#Stream的源的构建" class="headerlink" title="Stream的源的构建"></a>Stream的源的构建</h2><p>有多种方式可以构建流：</p><ol><li><p>静态工厂</p><ul><li>Stream.of()</li><li>IntStream.of()</li><li>LongStream.of()</li><li>DoubleStream.of()</li></ul></li><li><p>Collection 和 Array</p><ul><li>Collection.stream()</li><li>Collection.parallelStream()</li><li>Arrays.stream(T array)</li></ul></li><li><p>字符流</p><ul><li>BufferdReader.lines()</li></ul></li><li><p>文件路径</p><ul><li>Files.walk()</li><li>Files.lines()</li><li>Files.find()</li></ul></li><li><p>其它</p><ul><li>Random.ints()</li><li>BitSet.stream()</li><li>Pattern.splitAsStream(java.lang.CharSequence)</li><li>JarFile.stream()</li></ul></li></ol><p>生成流的时候，除了可以生成串行流，也可以生成并行流，即并行处理流的操作。</p><pre><code>final List&lt;String&gt; strings = Arrays.asList("ab", "a", "abc", "b", "bc");//串行流long count1 = strings.stream()    .filter(s -&gt; {        System.out.println("thread:" + Thread.currentThread().getId());        return s.startsWith("a");    })    .count();System.out.println(count1);//并行流long count2 = strings.parallelStream()    .filter(s -&gt; {        System.out.println("thread:" + Thread.currentThread().getId());        return s.startsWith("a");    })    .count();System.out.println(count2);</code></pre><h2 id="Stream操作的分类"><a href="#Stream操作的分类" class="headerlink" title="Stream操作的分类"></a>Stream操作的分类</h2><table><thead><tr><th align="left">Stream操作</th><th align="left">操作分类</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">中间操作(Intermediate operations)</td><td align="left">无状态(Stateless)</td><td align="left">unordered(), filter(), map(), mapToInt(), mapToLong(), mapToDouble(), flatMap(), flatMapToInt(), flatMapToLong(), flatMapToDouble(), peek();</td></tr><tr><td align="left">中间操作(Intermediate operations)</td><td align="left">有状态(Stateful)</td><td align="left">distinct();  sorted();  limit(), skip()</td></tr><tr><td align="left">终断操作(Terminal operations)</td><td align="left">非短路操作</td><td align="left">forEach(), forEachOrdered(); reduce(), collect(), max(), min(), count(); toArray()</td></tr><tr><td align="left">终断操作(Terminal operations)</td><td align="left">短路操作(short-circuiting)</td><td align="left">anyMatch(), allMatch(), noneMatch(); findFirst(), findAny()</td></tr></tbody></table><ul><li><p><strong>中间操作</strong></p><p>返回一个新的Stream。中间操作都是惰性的，它们不会对数据源执行任何操作，仅仅是创建一个新的Stream。在终断操作执行之前，数据源的遍历不会开始。</p></li><li><p><strong>终断操作</strong></p><p>遍历流并生成结果或者副作用。执行完终断操作后，Stream就会被“消费”掉，如果想再次遍历数据源，则必须重新创建新的Stream。大多数情况下，终断操作的遍历都是即时的——在返回之前完成数据源的遍历和处理，只有iterator()和spliterator()不是，这两个方法用于提供额外的遍历功能——让开发者自己控制数据源的遍历以实现现有Stream操作中无法满足的操作(实际上现有的Stream操作基本能满足需求，所以这两个方法目前用的不多)。</p></li></ul><h2 id="Stream的操作"><a href="#Stream的操作" class="headerlink" title="Stream的操作"></a>Stream的操作</h2><h3 id="中间操作"><a href="#中间操作" class="headerlink" title="中间操作"></a>中间操作</h3><h4 id="有状态操作"><a href="#有状态操作" class="headerlink" title="有状态操作"></a>有状态操作</h4><ul><li><strong>map</strong><blockquote><p>使用传入的Function对象对Stream中的所有元素进行处理，返回的Stream对象中的元素为原元素处理后的结果。</p></blockquote></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-02.jpg" alt=""></p><pre><code>// map，平方数List&lt;Integer&gt; nums = Arrays.asList(1, 2, 3, 4);Collection&lt;Integer&gt; squareNums = nums.stream()    .map(n -&gt; n * n)    .collect(Collectors.toList());squareNums.forEach(integer -&gt; System.out.println(integer));</code></pre><ul><li><strong>flatMap</strong><blockquote><p>map 生成的是个 1:1 映射，每个输入元素，都按照规则转换成为另外一个元素。flatMap，则是一对多映射关系的。</p></blockquote></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-03.jpg" alt=""></p><pre><code>Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of(        Arrays.asList(1),        Arrays.asList(2, 3),        Arrays.asList(4, 5, 6));List&lt;Integer&gt; integerStream = inputStream    .flatMap(list -&gt; list.stream())    .map(n -&gt; n * n)    .collect(Collectors.toList());integerStream.forEach(System.out::println);</code></pre><ul><li><strong>filter</strong><blockquote><p>filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream</p></blockquote></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-04.jpg" alt=""></p><pre><code>List&lt;String&gt; strings = Arrays.asList("ab", "a", "abc", "b", "bc");strings.stream()    .filter(s -&gt; s.startsWith("a"))    .forEach(System.out::println);</code></pre><ul><li><strong>peek</strong><blockquote><p>peek，遍历Stream中的元素，和forEach类似，区别是peek不会“消费”掉Stream，而forEach会消费掉Stream；peek是中间操作所以也是惰性的，只有在Stream“消费”的时候生效。</p></blockquote></li></ul><pre><code>// peekStream.of("one", "two", "three", "four")    .peek(e -&gt; System.out.println("原来的值: " + e))    .map(String::toUpperCase)    .peek(e -&gt; System.out.println("转换后的值: " + e))    .collect(Collectors.toList());</code></pre><ul><li><strong>limit 和 skip</strong><blockquote><p>limit取头部的数据(或者说截取前面的元素)<br>skip取尾部的数据(跳过前面的元素)</p></blockquote></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-05.jpg" alt=""></p><pre><code>//limit, 返回 Stream 的前面 n 个元素List&lt;String&gt; strings = Arrays.asList("ab", "a", "abc", "b", "bc");strings.stream()    .limit(3)    .forEach(System.out::println);System.out.println("==============");//skip 则是扔掉前 n 个元素strings.stream()    .skip(3)    .forEach(System.out::println);</code></pre><h4 id="无状态操作"><a href="#无状态操作" class="headerlink" title="无状态操作"></a>无状态操作</h4><ul><li><strong>distinct</strong><blockquote><p>去除重复的元素</p></blockquote></li></ul><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/md-images/java-stream-06.jpg" alt=""></p><pre><code>Stream&lt;String&gt; distinctString = Stream.of("a","b","b","c")    .distinct();distinctString.forEach(System.out::println);</code></pre><ul><li><strong>sorted</strong><blockquote><p>对Stream中的元素进行排序。<br>有两个重载方法，其中 Stream&lt;T&gt; sorted() 需要元素实现了Comparable接口。</p></blockquote></li></ul><pre><code>Arrays.asList("ab", "a", "abc", "b", "bc").stream()    .sorted()    .forEach(System.out::println);Arrays.asList("ab", "a", "abc", "b", "bc").stream()    .sorted((o1, o2) -&gt; {        return o1.compareTo(o2);    })    .forEach(System.out::println);</code></pre><h3 id="终端操作"><a href="#终端操作" class="headerlink" title="终端操作"></a>终端操作</h3><h4 id="短路操作"><a href="#短路操作" class="headerlink" title="短路操作"></a>短路操作</h4><p>短路操作其实就和我们日常编程用到的&amp;&amp;和||运算符处理过程类似，遇到一个满足条件的就立即停止判断。</p><ul><li><strong>anyMatch</strong><blockquote><p>只要其中有一个元素满足传入的Predicate时返回True，否则返回False。<br>前面的中间操作只要anyMatch中的条件成立后，就不再执行。与逻辑运算符 || 类似。</p></blockquote></li></ul><pre><code>boolean anyMatchReturn = Arrays.asList("ab", "a", "abc", "b", "bc").stream()    .peek(s -&gt; System.out.println(s))    .anyMatch(s -&gt; s.startsWith("b"));System.out.println(anyMatchReturn);</code></pre><p>运行结果:</p><pre><code>abaabcbtrue</code></pre><ul><li><strong>allMatch</strong><blockquote><p>所有元素均满足传入的Predicate时返回True，否则False。<br>只要allMatch条件有一个为false，中间操作将终止执行。与逻辑运算符&amp;&amp;类似</p></blockquote></li></ul><pre><code>boolean allMatchReturn = Arrays.asList("ab", "a", "abc", "b", "bc").stream()  .peek(s -&gt; System.out.println(s))  .allMatch(s -&gt; s.startsWith("b"));System.out.println(allMatchReturn);</code></pre><p>运行结果:</p><pre><code>abfalse</code></pre><ul><li><strong>noneMatch</strong><blockquote><p>所有元素均不满足传入的Predicate时返回True，否则False。<br>只要allMatch条件有一个为true，中间操作将终止执行。</p></blockquote></li></ul><pre><code>boolean noneMatchReturn = Arrays.asList("ab", "a", "abc", "b", "bc").stream()    .peek(s -&gt; System.out.println(s))    .noneMatch(s -&gt; s.startsWith("b"));System.out.println(noneMatchReturn);</code></pre><p>运行结果:</p><pre><code>abaabcbfalse</code></pre><h4 id="非短路操作"><a href="#非短路操作" class="headerlink" title="非短路操作"></a>非短路操作</h4><ul><li><strong>forEach</strong><blockquote><p>对所有元素进行迭代处理，无返回值</p></blockquote></li></ul><pre><code>Arrays.asList("ab", "a", "abc", "b", "bc")    .forEach(System.out::println);</code></pre><ul><li><strong>reduce</strong><blockquote><p>计算机术语规约，通过累加器accumulator，对前面的序列进行累计操作，并最终返回一个值。<br>累加器accumulator有两个参数，第一个是前一次累加的结果，第二个是前面集合的下一个元素。<br>通过reduce，可以实现 average, sum, min, max, count。</p></blockquote></li></ul><p>reduce 有三个重载方法：</p><ol><li><p><strong>T reduce(T identity, BinaryOperator&lt;T&gt; accumulator)</strong></p><blockquote><p>这里的identity是初始值。</p></blockquote><p> 下面将会把几个字符组装成一个字符串</p><pre><code> String concat = Stream.of("A", "B", "C", "D")     .reduce("H", (x, y) -&gt; {         System.out.println("x=" + x + ", y=" + y);         return x.concat(y);     }); System.out.println(concat);</code></pre><p> 输出结果：</p><pre><code> x=H, y=A x=HA, y=B x=HAB, y=C x=HABC, y=D HABCD</code></pre></li><li><p><strong>Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator)</strong></p><blockquote><p>由于没有初始值，这里输出Optional类型，避免空指针</p></blockquote><pre><code> Optional&lt;String&gt; concat2Optional = Stream.of("A", "B", "C", "D").reduce((x, y) -&gt; {     System.out.println("x=" + x + ", y=" + y);     return x.concat(y); }); System.out.println(concat2Optional.orElse("default"));</code></pre><p> 输出结果：</p><pre><code> x=A, y=B x=AB, y=C x=ABC, y=D ABCD</code></pre></li><li><p><strong>&lt;U&gt; U reduce(U identity, BiFunction&lt;U, ? super T, U&gt; accumulator, BinaryOperator&lt;U&gt; combiner)</strong></p><blockquote><p>这个方法非常复杂，下次再细讲</p></blockquote></li></ol><ul><li><strong>collect</strong><blockquote><p>collect方法可以通过收集器collector将流转化为其他形式，比如字符串、list、set、map。</p></blockquote></li></ul><p>collect有两个重载方法，其中一个是最常用的：</p><p><strong>&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector)</strong></p><p>官方为了我们转换方便，已经在Collectors类中封装了各种各样的collector，下面看一些常用的收集器。</p><p><strong><em>拼接字符串</em></strong></p><pre><code>String collect1 = Stream.of("A", "B", "C", "D")    .collect(Collectors.joining());System.out.println(collect1);</code></pre><p><strong><em>转成List</em></strong></p><pre><code>List&lt;String&gt; collect2 = Stream.of("A", "B", "C", "D")    .collect(Collectors.toList());</code></pre><p><strong><em>转成set</em></strong></p><pre><code>Set&lt;String&gt; collect3 = Stream.of("A", "B", "C", "D")    .collect(Collectors.toSet());</code></pre><p><strong><em>转成map</em></strong></p><p>Collectors的toMap方法签名如下所示，前一个mapper转换成map中的key,后一个mapper转换成map中的value</p><pre><code>Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(  Function&lt;? super T, ? extends K&gt; keyMapper,   Function&lt;? super T, ? extends U&gt; valueMapper)Map&lt;String, String&gt; collect3 = Stream.of("A", "B", "C", "D")    .collect(Collectors.toMap(        s -&gt; s,        s -&gt; s    ));</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 函数式编程 </tag>
            
            <tag> Stream </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java8 - 函数式编程之Optional</title>
      <link href="/articles/java/han-shu-shi-bian-cheng-zhi-optional.html"/>
      <url>/articles/java/han-shu-shi-bian-cheng-zhi-optional.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在某些情况下，首先要判断某个参数或者某个方法的返回值是否为null，才能继续操作该参数。</p><p>对于某些链式操作需要多次通过if语句判断是否为空，才能确保不抛出NullPointerException，这段非空判断的代码显得非常冗长和恶心。比如下面这段代码：</p><pre><code>String isoCode = "default";if (user != null) {    Address address = user.getAddress();    if (address != null) {        Country country = address.getCountry();        if (country != null) {            isocode = country.getIosCode();            if (isocode != null) {                isocode = isocode.toUpperCase();            }        }    }}</code></pre><p>在java 8里，JDK引入了一个Optional类，该类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。通过本文的学习，我们看下如何通过Optional类重写上面那段判空代码。</p><h2 id="Optional初始化"><a href="#Optional初始化" class="headerlink" title="Optional初始化"></a>Optional初始化</h2><p>Optional类的构造方法是私有方法，所以只能通过它的静态工厂方法进行初始化。它的初始化方法有如下几种：</p><ul><li><strong>&lt;T&gt; Optional&lt;T&gt; of(T value)</strong><blockquote><p>为非null的值创建一个Optional。如果传入参数为null，抛出NullPointerException。</p></blockquote></li></ul><pre><code>// 调用工厂方法创建Optional实例Optional&lt;String&gt; name = Optional.of("hello");// 传入参数为null，抛出NullPointerException.Optional&lt;String&gt; someNull = Optional.of(null);</code></pre><ul><li><strong>&lt;T&gt; Optional&lt;T&gt; ofNullable(T value)</strong><blockquote><p>为指定的值创建一个Optional，如果指定的值为null，则返回一个空的Optional。<br>它和 of 的区别是可以传null值。</p></blockquote></li></ul><pre><code>// 调用工厂方法创建Optional实例Optional&lt;String&gt; name = Optional.ofNullable("hello");// 传入参数为null，不抛出NullPointerException，返回一个空的Optional.Optional&lt;String&gt; someNull = Optional.ofNullable(null);</code></pre><ul><li><strong>&lt;T&gt; Optional&lt;T&gt; empty()</strong><blockquote><p>是 ofNullable静态工厂方法，传null值时的实现，返回一个空的Optional。</p></blockquote></li></ul><pre><code>Optional empty = Optional.empty();</code></pre><h2 id="Optional类的其它方法"><a href="#Optional类的其它方法" class="headerlink" title="Optional类的其它方法"></a>Optional类的其它方法</h2><ul><li><strong>boolean isPresent()</strong><blockquote><p>如果值存在返回true，否则返回false。</p></blockquote></li></ul><pre><code>// falseOptional&lt;String&gt; empty = Optional.ofNullable(null);System.out.println(empty.isPresent());// trueOptional&lt;String&gt; optionalS2 = Optional.of(s2);System.out.println(optionalS2.isPresent());</code></pre><ul><li><strong>T get()</strong><blockquote><p>如果Optional有值则将其返回，否则抛出NoSuchElementException</p></blockquote></li></ul><pre><code>// 获取helloOptional.of("hello").get();// 抛出NoSuchElementExceptionOptional.empty().get();</code></pre><ul><li><strong>void ifPresent (Consumer&lt;? super T&gt; consumer)</strong><blockquote><p>如果Optional实例有值则调用consumer，否则不做处理。</p></blockquote></li></ul><pre><code>//调用ifPresent方法里面的consumerOptional.of("hello")        .ifPresent(System.out::println);</code></pre><ul><li><strong>T orElse(T other)</strong><blockquote><p>如果有值则将其返回，否则返回指定的其它值</p></blockquote></li></ul><pre><code>// 输出nullSystem.out.println(Optional.empty().orElse("null"));// 输出helloSystem.out.println(Optional.of("hello").orElse("null"));</code></pre><ul><li><strong>T orElseGet (Supplier&lt;? extends T&gt; other)</strong><blockquote><p>orElseGet与orElse方法类似，区别在于得到的默认值。<br>orElse方法将传入的字符串作为默认值，<br>orElseGet方法可以接受 Supplier 接口的实现用来生成默认值。</p></blockquote></li></ul><pre><code>// 输出nullSystem.out.println(Optional.empty().orElseGet(() -&gt; "null"));// 输出helloSystem.out.println(Optional.of("hello").orElseGet(() -&gt; "null"));</code></pre><ul><li><strong>&lt;X extends Throwable&gt; T orElseThrow (Supplier&lt;? extends X&gt; exceptionSupplier) throws X</strong><blockquote><p>如果有值则将其返回，否则抛出 supplier 接口创建的异常。</p></blockquote></li></ul><pre><code>// 抛出exceptiontry {    Optional.empty()            .orElseThrow(()-&gt;new Exception("为空"));} catch (Exception e) {    e.printStackTrace();}</code></pre><ul><li><strong>&lt;U&gt; Optional&lt;U&gt; map (Function&lt;? super T, ? extends U&gt; mapper)</strong><blockquote><p>如果参数 mapper 有值，则调用map方法执行mapper参数的Function方法得到返回值。<br>如果mapper的返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。<br>如果传入的mapper参数是null，抛出NullPointerException。</p></blockquote></li></ul><pre><code>// 输出 JACKOptional&lt;String&gt; stringOptional = Optional.of("jack")    .map((value) -&gt; value.toUpperCase());System.out.println(stringOptional.orElse("default"));// 输出 defaultOptional&lt;String&gt; stringOptional1 = Optional.of("jack")    .map((value) -&gt; null);System.out.println(stringOptional1.orElse("default"));// 输出 default，并且不会调用mapperString s2 = null;Optional&lt;String&gt; stringOptional2 = Optional.ofNullable(s2)    .map((value) -&gt; value.toUpperCase());System.out.println(stringOptional2.orElse("default"));// 如果参数mapper为null，抛NullPointerException异常try {    String s3 = null;    Optional&lt;String&gt; stringOptional3 = Optional.ofNullable(s3)        .map(null);    System.out.println(stringOptional3.orElse("default"));} catch (Exception e) {}</code></pre><ul><li><strong>&lt;U&gt; Optional&lt;U&gt; flatMap (Function&lt;? super T, Optional&lt;U&gt;&gt; mapper)</strong><blockquote><p>flatMap与map方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。</p></blockquote></li></ul><pre><code>// flatMap，输出 JACKOptional&lt;String&gt; stringOptional4 = Optional.of("jack")    .flatMap(value -&gt; Optional.ofNullable(value.toUpperCase()));System.out.println(stringOptional4.orElse("default"));// flatMap，输出 defaultOptional&lt;String&gt; stringOptional5 = Optional.of("jack")    .flatMap(value -&gt; Optional.ofNullable(null));System.out.println(stringOptional5.orElse("default"));// flatMap，输出 default，并且不会调用mapperString s6 = null;Optional&lt;String&gt; stringOptional6 = Optional.ofNullable(s6)    .flatMap(value -&gt; Optional.ofNullable(value.toUpperCase()));System.out.println(stringOptional6.orElse("default"));// flatMap 如果map的参数mapper为null，抛NullPointerException异常try {    String s7 = null;    Optional&lt;String&gt; stringOptional7 = Optional.ofNullable(s7)        .flatMap(null);    System.out.println(stringOptional7.orElse("default"));} catch (Exception e) {    System.out.println("出错了");}</code></pre><ul><li><strong>Optional&lt;T&gt; filter (Predicate&lt;? super T&gt; predicate)</strong><blockquote><p>如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。</p></blockquote></li></ul><pre><code>// 输出defaultString filterString = Optional.of("hugo")        .filter(s -&gt; "jack".equals(s))        .orElse("default");System.out.println(filterString);// 输出hugoString filterString2 = Optional.of("hugo")        .filter(s -&gt; "hugo".equals(s))        .orElse("default");System.out.println(filterString2);// 输出default，断言接口里面的语句不会执行String nullableString = null;String filterString3 = Optional.ofNullable(nullableString)        .filter(s -&gt; {            System.out.println("测试是否调用");            return "jack".equals(s);        })        .orElse("default");System.out.println(filterString3);</code></pre><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>经过上面学习Optional的相关API，已经对它有了一定的了解。下面，我们运用上面的知识解决在前言中遗留的问题。</p><pre><code>ioscode = Optional.ofNullable(user)        .map(u -&gt; u.getAddress())        .map(addr -&gt; addr.getCountry())        .map(country -&gt; country.getIosCode())        .map(String::toUpperCase)        .orElse("default");</code></pre><p>从上面的学习可以知道，只有Optional是empty的，map方法不会被调用。</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 函数式编程 </tag>
            
            <tag> Optional </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java8 - 函数式编程之Lambda</title>
      <link href="/articles/java/han-shu-shi-bian-cheng-zhi-lambda.html"/>
      <url>/articles/java/han-shu-shi-bian-cheng-zhi-lambda.html</url>
      
        <content type="html"><![CDATA[<p>Lambda表达式是Java8的新语法糖。它其实是一个匿名函数，可以把Lambda表达式理解为一段约定好怎么传递参数和返回参数的一段代码，由编译器负责参数类型的猜测并执行结果。我们通过lambda表达式可以写出更简洁、更灵活的代码。</p><h2 id="Lambda-表达式语法"><a href="#Lambda-表达式语法" class="headerlink" title="Lambda 表达式语法"></a>Lambda 表达式语法</h2><h3 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h3><blockquote><p>“-&gt;” 操作符将 Lambda 表达式分为两个部分：左侧为参数列表，右侧为 Lambda 体。</p></blockquote><pre><code># Lambda 体，单行表达式，直接写在 “-&gt;” 右侧(parameters) -&gt; expression# Lambda 体，有多行表达式，用 “{}” 包含起来(parameters) -&gt; { statements; }</code></pre><h3 id="具体的语法"><a href="#具体的语法" class="headerlink" title="具体的语法"></a>具体的语法</h3><table><thead><tr><th align="left">场景</th><th align="left">案例</th></tr></thead><tbody><tr><td align="left">无参数，无返回值</td><td align="left">() -&gt; System.out.println(“Helo”);</td></tr><tr><td align="left">无参数，有返回值</td><td align="left">() -&gt; 10;</td></tr><tr><td align="left">有一个参数，无返回值</td><td align="left">x -&gt; System.out.print(x);</td></tr><tr><td align="left">有一个参数，有返回值</td><td align="left">x -&gt; x + 10;</td></tr><tr><td align="left">有多个参数，没有返回值</td><td align="left">(x, y) -&gt; System.out.println(x + y);</td></tr><tr><td align="left">有多个参数，有返回值</td><td align="left">(x, y) -&gt; x + y;</td></tr></tbody></table><p>其实，每个lambda表达式的返回值都是一个函数式编程的接口。</p><h2 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h2><ul><li>无参数，无返回值</li></ul><pre><code>Runnable runnable = () -&gt; System.out.println("hello");new Thread(runnable).start();</code></pre><ul><li>无参数，有返回值</li></ul><pre><code>Supplier&lt;Integer&gt; supplier = () -&gt; 10;Integer number = supplier.get();System.out.println(number);</code></pre><ul><li>有一个参数，无返回值</li></ul><pre><code>Consumer&lt;String&gt; consumer = x -&gt; System.out.println(x);or Consumer&lt;String&gt; consumer = (x) -&gt; System.out.println(x);or Consumer&lt;String&gt; consumer = (x) -&gt; {    System.out.println(x);};consumer.accept("hello");</code></pre><ul><li>有一个参数，有返回值</li></ul><pre><code>Function&lt;Integer,Integer&gt; function = x -&gt; x + 10;orFunction&lt;Integer,Integer&gt; function = (x) -&gt; x + 10;orFunction&lt;Integer, Integer&gt; function = (x) -&gt; {    return x + 10;};int result = function.apply(20);System.out.println(result);</code></pre><ul><li>多个参数，没有返回值</li></ul><pre><code>BiConsumer&lt;Integer, String&gt; consumer = (x, y) -&gt; {    System.out.println(x);    System.out.println(y);};orBiConsumer&lt;Integer, String&gt; consumer = (Integer x, String y) -&gt; {    System.out.println(x);    System.out.println(y);};consumer.accept(100, "hello");</code></pre><ul><li>多个参数，有返回值</li></ul><pre><code>BiFunction&lt;Integer, Integer, Integer&gt; function = (x, y) -&gt; x + y;orBiFunction&lt;Integer, Integer, Integer&gt; function = (Integer x, Integer y) -&gt; x + y;orBiFunction&lt;Integer, Integer, Integer&gt; function = (Integer x, Integer y) -&gt; {    return x + y;};int result = function.apply(10, 10);System.out.println(result);</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 函数式编程 </tag>
            
            <tag> Lambda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java8 - 函数式编程之基本接口</title>
      <link href="/articles/java/han-shu-shi-bian-cheng-zhi-ji-ben-jie-kou.html"/>
      <url>/articles/java/han-shu-shi-bian-cheng-zhi-ji-ben-jie-kou.html</url>
      
        <content type="html"><![CDATA[<p>不管lambda表达式还是Stream流式编程，Function、Consumer、Supplier、Predicate 四个接口是一切函数式编程的基础。</p><p><img src="https://cdn.jsdelivr.net/gh/lvmaohai/blog/images/java-function-01.jpg" alt=""></p><ul><li>Supplier<t>：T get()；无输入，“生产”一个T类型的返回值。</t></li><li>Consumer<t>：void accept(T t)；输入类型T，“消费”掉，无返回。</t></li><li>Function&lt;T, R&gt;：R apply(T t)；输入类型T返回类型R。</li><li>Predicate<t>：boolean test(T t)；输入类型T，并进行条件“判断”，返回true|false。</t></li></ul><h2 id="interface-Supplier-lt-T-gt"><a href="#interface-Supplier-lt-T-gt" class="headerlink" title="interface Supplier<T>"></a>interface Supplier&lt;T&gt;</h2><blockquote><p>该接口的中文直译是“提供者”，可以理解为定义一个lambda表达式，没有输入参数，返回一个T类型的值。</p></blockquote><pre><code>Supplier&lt;Integer&gt; supplier = () -&gt; 10;// 输出10System.out.println(supplier.get());</code></pre><h2 id="interface-Consumer-lt-T-gt"><a href="#interface-Consumer-lt-T-gt" class="headerlink" title="interface Consumer<T>"></a>interface Consumer&lt;T&gt;</h2><blockquote><p>该接口的中文直译是“消费”，可以理解为定义一个lambda表达式，接收一个T类型的参数，并且没有返回值。</p></blockquote><ul><li><strong>accept</strong> ：接收参数，并调用Consumer接口里的方法</li></ul><pre><code>Consumer&lt;Integer&gt; consumer = x -&gt; System.out.println(x);// 输出10consumer.accept(10);</code></pre><ul><li><strong>andThen</strong>：调用完consumer自己后，还调用andThen方法参数中指定的Consumer</li></ul><pre><code>Consumer&lt;Integer&gt; consumer = x -&gt; System.out.println(x);Consumer&lt;Integer&gt; plusSelf = x -&gt; System.out.println(x + x);// 输出10以及20consumer.andThen(plusSelf).accept(10);</code></pre><h2 id="interface-Function-lt-T-R-gt"><a href="#interface-Function-lt-T-R-gt" class="headerlink" title="interface Function<T, R>"></a>interface Function&lt;T, R&gt;</h2><blockquote><p>该接口的中文直译是“函数”，可以理解为：定义一个lambda表达式，接收一个T类型的参数，返回一个R类型的值。</p></blockquote><ul><li><strong>apply</strong>：传入一个T类型的参数，返回一个R类型的值</li></ul><pre><code>Function&lt;Integer, Integer&gt; function = x -&gt; x + x;// 输出20System.out.println(function.apply(10));</code></pre><ul><li><strong>compose</strong>：accept获取到的参数，先执行compose里面的Function，再执行原Function</li></ul><pre><code>Function&lt;Integer, Integer&gt; plusSelf = x -&gt; {    System.out.println("plusSelf");    return x + x;};Function&lt;Integer, String&gt; toString = x -&gt; {    System.out.println("toString");    return String.valueOf(x);};// 输出20，整数10先自加变成20，然后由toString转换成字符串String string1 = toString.compose(plusSelf).apply(10);System.out.println(string1);</code></pre><ul><li><strong>andThen</strong>：与compose相反。先执行原Function，在执行andThen里面的Function。</li></ul><pre><code>Function&lt;Integer, Integer&gt; plusSelf = x -&gt; {    System.out.println("plusSelf");    return x + x;};Function&lt;Integer, String&gt; toString = x -&gt; {    System.out.println("toString");    return String.valueOf(x);};// 输出20, 先自加，再转换成字符串String string2 = plusSelf.andThen(toString).apply(10);System.out.println(string2);</code></pre><h2 id="interface-Predicate-lt-T-gt"><a href="#interface-Predicate-lt-T-gt" class="headerlink" title="interface Predicate<T>"></a>interface Predicate&lt;T&gt;</h2><blockquote><p>该接口的中文直译是“断言”，用于返回false/true。T是lambda表达式的输入参数类型。</p></blockquote><ul><li><strong>test</strong>：测试test方法中输入参数是否满足接口中定义的lambda表达式</li></ul><pre><code>Predicate&lt;String&gt; test = x -&gt; "test".equals(x);Predicate&lt;String&gt; test2 = x -&gt; "test2".equals(x);// 输出 trueSystem.out.println(test.test("test"));// 输出 falseSystem.out.println(test.test("test_false"));</code></pre><ul><li><strong>and</strong>：原 Predicate 接口和 and 方法中指定的 Predicate 接口要同时为true，test方法才为true。与逻辑运算符 &amp;&amp; 一致。</li></ul><pre><code>Predicate&lt;String&gt; test = x -&gt; "test".equals(x);Predicate&lt;String&gt; test2 = x -&gt; "test2".equals(x);// 输出 falseSystem.out.println(test.and(test2).test("test"));</code></pre><ul><li><strong>negate</strong>：对结果取反后再输出</li></ul><pre><code>Predicate&lt;String&gt; test = x -&gt; "test".equals(x);Predicate&lt;String&gt; test2 = x -&gt; "test2".equals(x);// 输出 falseSystem.out.println(test.negate().test("test"));</code></pre><ul><li><strong>or</strong>：原 Predicate 接口和 or 方法中指定的 Predicate 接口只要一个为true，test方法为true。与逻辑运算符 || 一致。</li></ul><pre><code>Predicate&lt;String&gt; test = x -&gt; "test".equals(x);Predicate&lt;String&gt; test2 = x -&gt; "test2".equals(x);// 输出 falseSystem.out.println(test.or(test2).test("test"));</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 函数式编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java8 - 函数式编程之简介</title>
      <link href="/articles/java/han-shu-shi-bian-cheng-zhi-jian-jie.html"/>
      <url>/articles/java/han-shu-shi-bian-cheng-zhi-jian-jie.html</url>
      
        <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>简单说，”函数式编程”是一种”编程范式”（programming paradigm），也就是如何编写程序的方法论。</p><p>它属于”结构化编程”的一种，主要思想是把运算过程尽量写成一系列嵌套的函数调用。举例来说，现在有这样一个数学表达式：</p><pre><code>(1 + 2) * 3 - 4</code></pre><p>传统的过程式编程，可能这样写：</p><pre><code>var a = 1 + 2;var b = a * 3;var c = b - 4;</code></pre><p>函数式编程要求使用函数，我们可以把运算过程定义为不同的函数，然后写成下面这样：</p><pre><code>var result = subtract(multiply(add(1,2), 3), 4);</code></pre><p>这就是函数式编程。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ol><li><p>函数是”第一等公民”</p><p> 所谓”第一等公民”（first class），指的是函数与其他数据类型一样，处于平等地位，可以赋值给其他变量，也可以作为参数，传入另一个函数，或者作为别的函数的返回值。</p><p> 举例来说，下面代码中的print变量就是一个函数，可以作为另一个函数的参数。</p><pre><code> var print = function(i) {    console.log(i); }; [1,2,3].forEach(print);</code></pre></li><li><p>只用”表达式”，不用”语句”</p><p> “表达式”（expression）是一个单纯的运算过程，总是有返回值；”语句”（statement）是执行某种操作，没有返回值。函数式编程要求，只使用表达式，不使用语句。也就是说，每一步都是单纯的运算，而且都有返回值。</p><p> 原因是函数式编程的开发动机，一开始就是为了处理运算（computation），不考虑系统的读写（I/O）。”语句”属于对系统的读写操作，所以就被排斥在外。</p><p> 当然，实际应用中，不做I/O是不可能的。因此，编程过程中，函数式编程只要求把I/O限制到最小，不要有不必要的读写行为，保持计算过程的单纯性。</p></li><li><p>没有”副作用”</p><p> 所谓”副作用”（side effect），指的是函数内部与外部互动（最典型的情况，就是修改全局变量的值），产生运算以外的其他结果。</p><p> 函数式编程强调没有”副作用”，意味着函数要保持独立，所有功能就是返回一个新的值，没有其他行为，尤其是不得修改外部变量的值.</p></li><li><p>不修改状态<br> 函数式编程只是返回新的值，不修改系统变量。</p><p> 在其他类型的语言中，变量往往用来保存”状态”（state）。不修改变量，意味着状态不能保存在变量中。函数式编程使用参数保存状态，最好的例子就是递归。</p></li><li><p>引用透明</p><p> 引用透明（Referential transparency），指的是函数的运行不依赖于外部变量或”状态”，只依赖于输入的参数，任何时候只要参数相同，引用函数所得到的返回值总是相同的。</p><p> 其他类型的语言，函数的返回值往往与系统状态有关，不同的状态之下，返回值是不一样的。这就叫”引用不透明”，很不利于观察和理解程序的行为。</p></li></ol><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ol><li><p>代码简洁，开发快速</p></li><li><p>接近自然语言，易于理解<br> (1+2)*3-4用函数式语言表达</p><pre><code> add(1,2).multiply(3).subtract(4)</code></pre></li><li><p>更方便的代码管理</p><p> 不依赖、也不会改变外界的状态，只要给定输入参数，返回的结果必定相同。因此，每一个函数都可以被看做独立单元，很有利于进行单元测试（unit testing）和除错（debugging），以及模块化组合。</p></li><li><p>易于”并发编程”<br> 函数式编程不需要考虑”死锁”（deadlock），因为它不修改变量，所以根本不存在”锁”线程的问题。不必担心一个线程的数据，被另一个线程修改，所以可以很放心地把工作分摊到多个线程，部署”并发编程”（concurrency）。</p></li></ol><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 函数式编程 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
